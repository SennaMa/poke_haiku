{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Downloading cohere-4.34-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting aiohttp<4.0,>=3.0 (from cohere)\n",
      "  Downloading aiohttp-3.8.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting backoff<3.0,>=2.0 (from cohere)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting fastavro==1.8.2 (from cohere)\n",
      "  Downloading fastavro-1.8.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.5 kB)\n",
      "Collecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cohere) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cohere) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (3.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0,>=3.0->cohere)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4.0,>=3.0->cohere)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0,>=3.0->cohere)\n",
      "  Downloading yarl-1.9.2-cp311-cp311-macosx_11_0_arm64.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0,>=3.0->cohere)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0,>=3.0->cohere)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting zipp>=0.5 (from importlib_metadata<7.0,>=6.0->cohere)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n",
      "Downloading cohere-4.34-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.8.2-cp311-cp311-macosx_10_9_universal2.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.1/922.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp311-cp311-macosx_11_0_arm64.whl (343 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.5/343.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: zipp, multidict, frozenlist, fastavro, backoff, async-timeout, yarl, importlib_metadata, aiosignal, aiohttp, cohere\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 backoff-2.2.1 cohere-4.34 fastavro-1.8.2 frozenlist-1.4.0 importlib_metadata-6.8.0 multidict-6.0.4 yarl-1.9.2 zipp-3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'personal_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m co \u001b[39m=\u001b[39m cohere\u001b[39m.\u001b[39mClient(personal_token) \u001b[39m# This is your trial API key\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m response \u001b[39m=\u001b[39m co\u001b[39m.\u001b[39mgenerate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m5b6dd549-d87e-4d8c-a192-c41595c84840-ft\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   prompt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGenerate a haiku about the mountain and fairy Pokemon called \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mCLEFAIRY\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Here is a description about Clefairy: On every night of a full moon, groups of this POKéMON come out to play. When dawn arrives, the tired CLEFAIRY return to their quiet mountain retreats and go to sleep nestled up against each other.\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   stop_sequences\u001b[39m=\u001b[39m[],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   return_likelihoods\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNONE\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/senna/poke_haiku/project/haiku_generator/haiku_generator.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPrediction:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(response\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'personal_token' is not defined"
     ]
    }
   ],
   "source": [
    "co = cohere.Client(personal_token) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt='Generate a haiku about the mountain and fairy Pokemon called \\\"CLEFAIRY\\\". Here is a description about Clefairy: On every night of a full moon, groups of this POKéMON come out to play. When dawn arrives, the tired CLEFAIRY return to their quiet mountain retreats and go to sleep nestled up against each other.\\\"\\\"',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=66,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " A city's heart,\n",
      "A Pokemon of light.\n",
      "A ball of fire.\n"
     ]
    }
   ],
   "source": [
    "# picked the 100th pokemon\n",
    "\n",
    "prompt_description = \"VOLTORB is extremely sensitive - it explodes at the slightest of shocks. It is rumored that it was first created when a POKé BALL was exposed to a powerful pulse of energy.\"\n",
    "prompt_pokemon = 'VOLTORB'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the urban and electric Pokemon called {prompt_pokemon}. Here is a description about {prompt_pokemon}: {prompt_description}. Use {prompt_pokemon} in the haiku.',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=66,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " A rare, psychic Pokmon,\n",
      "The body of a Pokmon\n",
      "The heart of a human.\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"MEWTWO is a POKéMON that was created by genetic manipulation. However, even though the scientific power of humans created MEWTWO's body, they failed to endow MEWTWO with a compassionate heart.\"\n",
    "prompt_pokemon = \"MEWTWO\"\n",
    "habitat = 'rare'\n",
    "pokemon_type = 'psychic'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the {habitat}, {pokemon_type} Pokemon called {prompt_pokemon}. Here is a description about {prompt_pokemon}: {prompt_description}. Use {prompt_pokemon} in the haiku.',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=66,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " A single Chancey,\n",
      "\n",
      "Is the sign of a happy trainer.\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"Few in number and difficult to cap­ture, it is said to bring happiness to the trainer who catches it.\"\n",
    "prompt_pokemon = \"CHANSEY\"\n",
    "egg_type = 'fairy'\n",
    "pokemon_type = 'normal'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the {egg_type} {pokemon_type} Pokemon called {prompt_pokemon}. Here is a description about {prompt_pokemon}: {prompt_description}',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=66,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " The ground-fire Pokemon,\n",
      "\n",
      "VULPIX\n",
      "\n",
      "Is filled with a wonder.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"Its nine beautiful tails are filled with a wondrous energy that could keep it alive for 1,000 years.\"\n",
    "prompt_pokemon = \"VULPIX\"\n",
    "egg_type = 'ground'\n",
    "pokemon_type = 'fire'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the {egg_type} {pokemon_type} Pokemon called {prompt_pokemon}. Here is a description about {prompt_pokemon}: {prompt_description}.',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=70,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " In the grassland,\n",
      "A fire-breathing\n",
      "Giant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"Its nine beautiful tails are filled with a wondrous energy that could keep it alive for 1,000 years.\"\n",
    "prompt_pokemon = \"VULPIX\"\n",
    "egg_type = 'ground'\n",
    "pokemon_type = 'fire'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the the {egg_type} {pokemon_type} Pokemon, called \"{prompt_pokemon}\" and grassland',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=70,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " Through its nose\n",
      "It sucks in the emanations\n",
      "Of the angry people\n",
      "And Pokémon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"Through its nose, it sucks in the emanations produced by people and Pokémon when they feel annoyed. It thrives off this negative energy.\"\n",
    "prompt_pokemon = \"IMPIDIMP\"\n",
    "egg_type = 'fairy'\n",
    "pokemon_type = 'dark fairy'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the the {egg_type} {pokemon_type} Pokemon, called \"{prompt_pokemon}\" using this description: {prompt_description}',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=70,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " AERODACTYL\n",
      "Shrieked high-pitched cries\n",
      "In ancient skies.\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"This vicious pokemon is said to have flown in ancient skies while shrieking high-pitched cries.\"\n",
    "prompt_pokemon = \"AERODACTYL\"\n",
    "pokemon_type = 'flying rock'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the {pokemon_type} Pokemon, called \"{prompt_pokemon}\" using this description: {prompt_description}',\n",
    "  max_tokens=30,\n",
    "  temperature=0.8,\n",
    "  k=50,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " The mankey, a Pokemon of anger\n",
      "Is the very quick to anger\n",
      "It thrashes away the next instant\n"
     ]
    }
   ],
   "source": [
    "prompt_description = \"Extremely quick to anger. It could be docile one moment then thrashing away the next instant.\"\n",
    "prompt_pokemon = \"MANKEY\"\n",
    "pokemon_type = 'fighting pig monkey'\n",
    "\n",
    "response = co.generate(\n",
    "  model='5b6dd549-d87e-4d8c-a192-c41595c84840-ft',\n",
    "  prompt=f'Generate a haiku about the {pokemon_type} Pokemon, called \"{prompt_pokemon}\" using this description: {prompt_description}',\n",
    "  max_tokens=30,\n",
    "  temperature=0.80,\n",
    "  k=60,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction:\\n{}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
